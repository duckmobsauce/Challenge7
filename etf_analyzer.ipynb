{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Web Application for an ETF Analyzer\n",
    "\n",
    "In this Challenge assignment, you’ll build a financial database and web application by using SQL, Python, and the Voilà library to analyze the performance of a hypothetical fintech ETF.\n",
    "\n",
    "Instructions: \n",
    "\n",
    "Use this notebook to complete your analysis of a fintech ETF that consists of four stocks: GOST, GS, PYPL, and SQ. Each stock has its own table in the `etf.db` database, which the `Starter_Code` folder also contains.\n",
    "\n",
    "Analyze the daily returns of the ETF stocks both individually and as a whole. Then deploy the visualizations to a web application by using the Voilà library.\n",
    "\n",
    "The detailed instructions are divided into the following parts:\n",
    "\n",
    "* Analyze a single asset in the ETF\n",
    "\n",
    "* Optimize data access with Advanced SQL queries\n",
    "\n",
    "* Analyze the ETF portfolio\n",
    "\n",
    "* Deploy the notebook as a web application\n",
    "\n",
    "#### Analyze a Single Asset in the ETF\n",
    "\n",
    "For this part of the assignment, you’ll use SQL queries with Python, Pandas, and hvPlot to analyze the performance of a single asset from the ETF.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame.\n",
    "\n",
    "2. Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis.\n",
    "\n",
    "3. Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "4. Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "#### Optimize Data Access with Advanced SQL Queries\n",
    "\n",
    "For this part of the assignment, you’ll continue to analyze a single asset (PYPL) from the ETF. You’ll use advanced SQL queries to optimize the efficiency of accessing data from the database.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "2. Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "#### Analyze the ETF Portfolio\n",
    "\n",
    "For this part of the assignment, you’ll build the entire ETF portfolio and then evaluate its performance. To do so, you’ll build the ETF portfolio by using SQL joins to combine all the data for each asset.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame.\n",
    "\n",
    "2. Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame.\n",
    "\n",
    "    > **Hint** Assuming that this ETF contains equally weighted returns, you can average the returns for each asset to get the average returns of the portfolio. You can then use the average returns of the portfolio to calculate the annualized returns and the cumulative returns. For the calculation to get the average daily returns for the portfolio, use the following code:\n",
    "    >\n",
    "    > ```python\n",
    "    > etf_portfolio_returns = etf_portfolio['daily_returns'].mean(axis=1)\n",
    "    > ```\n",
    "    >\n",
    "    > You can use the average daily returns of the portfolio the same way that you used the daily returns of a single asset.\n",
    "\n",
    "3. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio.\n",
    "\n",
    "> **Hint**  To calculate the annualized returns, multiply the mean of the `etf_portfolio_returns` values by 252.\n",
    ">\n",
    "> To convert the decimal values to percentages, multiply the results by 100.\n",
    "\n",
    "4. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio.\n",
    "\n",
    "5. Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "#### Deploy the Notebook as a Web Application\n",
    "\n",
    "For this part of the assignment, complete the following steps:\n",
    "\n",
    "1. Use the Voilà library to deploy your notebook as a web application. You can deploy the web application locally on your computer.\n",
    "\n",
    "2. Take a screen recording or screenshots to show how the web application appears when using Voilà. Include the recording or screenshots in the `README.md` file for your GitHub repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the following code which imports the required libraries, initiates your SQLite database, popluates the database with records from the `etf.db` seed file that was included in your Starter_Code folder, creates the database engine, and confirms that data tables that it now contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/8k82k8t57kj6gq7_5y0znj_w0000gn/T/ipykernel_37361/1952660604.py:16: SADeprecationWarning: The Engine.table_names() method is deprecated and will be removed in a future release.  Please refer to Inspector.get_table_names(). (deprecated since: 1.4)\n",
      "  engine.table_names()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GDOT', 'GS', 'PYPL', 'SQ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required libraries and dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import sqlalchemy\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "\n",
    "# Create a temporary SQLite database and populate the database with content from the etf.db seed file\n",
    "database_connection_string = 'sqlite:///etf.db'\n",
    "\n",
    "# Create an engine to interact with the SQLite database\n",
    "engine = sqlalchemy.create_engine(database_connection_string)\n",
    "\n",
    "# Confirm that table names contained in the SQLite database.\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze a single asset in the FinTech ETF\n",
    "\n",
    "For this part of the assignment, you’ll use SQL queries with Python, Pandas, and hvPlot to analyze the performance of a single asset from the ETF.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame.\n",
    "\n",
    "2. Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis.\n",
    "\n",
    "3. Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "4. Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a SQL query to SELECT all of the data from the PYPL table\n",
    "query = \"\"\"\n",
    "    SELECT * FROM PYPL\n",
    "\"\"\"\n",
    "\n",
    "# Use the query to read the PYPL data into a Pandas DataFrame\n",
    "column_list = ['time', 'open', 'high', 'low', 'close', 'volume', 'daily_returns']\n",
    "pypl_dataframe = pd.DataFrame(engine.execute(query), columns=column_list)\n",
    "pypl_dataframe['time'] = pd.to_datetime(pypl_dataframe['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>39.90</td>\n",
       "      <td>39.90</td>\n",
       "      <td>39.12</td>\n",
       "      <td>39.32</td>\n",
       "      <td>7298861</td>\n",
       "      <td>-0.005564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>39.40</td>\n",
       "      <td>39.80</td>\n",
       "      <td>39.11</td>\n",
       "      <td>39.45</td>\n",
       "      <td>3436478</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>39.61</td>\n",
       "      <td>39.74</td>\n",
       "      <td>39.26</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2940991</td>\n",
       "      <td>0.007351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>39.84</td>\n",
       "      <td>40.74</td>\n",
       "      <td>39.82</td>\n",
       "      <td>40.09</td>\n",
       "      <td>5826704</td>\n",
       "      <td>0.008807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>40.04</td>\n",
       "      <td>40.09</td>\n",
       "      <td>39.54</td>\n",
       "      <td>39.68</td>\n",
       "      <td>4338385</td>\n",
       "      <td>-0.010227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time   open   high    low  close   volume  daily_returns\n",
       "0 2016-12-16  39.90  39.90  39.12  39.32  7298861      -0.005564\n",
       "1 2016-12-19  39.40  39.80  39.11  39.45  3436478       0.003306\n",
       "2 2016-12-20  39.61  39.74  39.26  39.74  2940991       0.007351\n",
       "3 2016-12-21  39.84  40.74  39.82  40.09  5826704       0.008807\n",
       "4 2016-12-22  40.04  40.09  39.54  39.68  4338385      -0.010227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the first 5 rows of the DataFrame.\n",
    "# YOUR CODE HERE\n",
    "display(pypl_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>212.51</td>\n",
       "      <td>215.83</td>\n",
       "      <td>207.0900</td>\n",
       "      <td>214.200</td>\n",
       "      <td>8992681</td>\n",
       "      <td>0.013629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>217.15</td>\n",
       "      <td>220.57</td>\n",
       "      <td>214.3401</td>\n",
       "      <td>216.520</td>\n",
       "      <td>9148174</td>\n",
       "      <td>0.010831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>215.60</td>\n",
       "      <td>215.75</td>\n",
       "      <td>210.5000</td>\n",
       "      <td>212.660</td>\n",
       "      <td>6414746</td>\n",
       "      <td>-0.017827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>213.33</td>\n",
       "      <td>216.93</td>\n",
       "      <td>213.1100</td>\n",
       "      <td>214.680</td>\n",
       "      <td>6463339</td>\n",
       "      <td>0.009499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>214.88</td>\n",
       "      <td>217.28</td>\n",
       "      <td>213.0100</td>\n",
       "      <td>217.235</td>\n",
       "      <td>2118319</td>\n",
       "      <td>0.011901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          time    open    high       low    close   volume  daily_returns\n",
       "994 2020-11-30  212.51  215.83  207.0900  214.200  8992681       0.013629\n",
       "995 2020-12-01  217.15  220.57  214.3401  216.520  9148174       0.010831\n",
       "996 2020-12-02  215.60  215.75  210.5000  212.660  6414746      -0.017827\n",
       "997 2020-12-03  213.33  216.93  213.1100  214.680  6463339       0.009499\n",
       "998 2020-12-04  214.88  217.28  213.0100  217.235  2118319       0.011901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the last 5 rows of the DataFrame.\n",
    "# YOUR CODE HERE\n",
    "display(pypl_dataframe.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m plot\u001b[38;5;241m.\u001b[39mopts(\n\u001b[1;32m     16\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     17\u001b[0m     ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily Returns\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[hover_daily_pypl]\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the image\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mhvplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImages/PYPL_Daily_Returns.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Display the plot\u001b[39;00m\n\u001b[1;32m     23\u001b[0m plot\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/util/__init__.py:820\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, filename, fmt, backend, resources, toolbar, title, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m formats[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m supported:\n\u001b[1;32m    819\u001b[0m         filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(formats[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/plotting/renderer.py:627\u001b[0m, in \u001b[0;36mRenderer.save\u001b[0;34m(self_or_cls, obj, basename, fmt, key, info, options, resources, title, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m     plot\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39msave(basename, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, resources\u001b[38;5;241m=\u001b[39mresources, title\u001b[38;5;241m=\u001b[39mtitle)\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 627\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[43mself_or_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rendered \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    629\u001b[0m (data, info) \u001b[38;5;241m=\u001b[39m rendered\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/plotting/renderer.py:201\u001b[0m, in \u001b[0;36mRenderer.__call__\u001b[0;34m(self, obj, fmt, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_html(plot), info\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_figure_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_post_render_hooks(data, obj, fmt)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, info\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/plotting/bokeh/renderer.py:131\u001b[0m, in \u001b[0;36mBokehRenderer._figure_data\u001b[0;34m(self, plot, fmt, doc, as_script, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbokeh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_screenshot_as_png\n\u001b[0;32m--> 131\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mget_screenshot_as_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwebdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     imgByteArr \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[1;32m    133\u001b[0m     img\u001b[38;5;241m.\u001b[39msave(imgByteArr, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPNG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/export.py:236\u001b[0m, in \u001b[0;36mget_screenshot_as_png\u001b[0;34m(obj, driver, timeout, resources, width, height)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    234\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(html)\n\u001b[0;32m--> 236\u001b[0m web_driver \u001b[38;5;241m=\u001b[39m driver \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mwebdriver_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m web_driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[1;32m    238\u001b[0m web_driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmp\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py:153\u001b[0m, in \u001b[0;36m_WebdriverState.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py:157\u001b[0m, in \u001b[0;36m_WebdriverState.create\u001b[0;34m(self, kind)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kind: DriverKind \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m WebDriver:\n\u001b[0;32m--> 157\u001b[0m     driver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drivers\u001b[38;5;241m.\u001b[39madd(driver)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m driver\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py:175\u001b[0m, in \u001b[0;36m_WebdriverState._create\u001b[0;34m(self, kind)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirefox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m driver\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeither firefox and geckodriver nor a variant of chromium browser and \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    176\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromedriver are available on system PATH. You can install the former \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    177\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install -c conda-forge firefox geckodriver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m driver_kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromium\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_chromium_webdriver()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'."
     ]
    }
   ],
   "source": [
    "hover_daily_pypl = HoverTool(tooltips=[(\"Date\",  \"@time{%m/%d/%Y}\"),\n",
    "                            (\"Daily Returns\", \"@daily_returns{0,0.000}\")\n",
    "                           ],\n",
    "                  formatters = {\n",
    "                            '@time': 'datetime'\n",
    "                  }\n",
    "                 )\n",
    "# Create an interactive visualization with hvplot to plot the daily returns for PYPL.\n",
    "plot = pypl_dataframe.hvplot(\n",
    "    title=f'PYPL Daily Returns: {pypl_dataframe[\"time\"].min().date()} to {pypl_dataframe[\"time\"].max().date()}', \n",
    "    x='time', \n",
    "    y='daily_returns',\n",
    "    rot = 45\n",
    ")\n",
    "plot.opts(\n",
    "    xlabel='Time', \n",
    "    ylabel='Daily Returns',\n",
    "    tools=[hover_daily_pypl]\n",
    ")\n",
    "# Save the image\n",
    "hvplot.save(plot, 'Images/PYPL_Daily_Returns.png')\n",
    "# Display the plot\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m plot\u001b[38;5;241m.\u001b[39mopts(\n\u001b[1;32m     18\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Return\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[hover_cum_pypl]\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Save the image\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mhvplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImages/PYPL_Cumulative_Returns.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Display the plot\u001b[39;00m\n\u001b[1;32m     25\u001b[0m plot\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/util/__init__.py:820\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, filename, fmt, backend, resources, toolbar, title, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m formats[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m supported:\n\u001b[1;32m    819\u001b[0m         filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(formats[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/plotting/renderer.py:627\u001b[0m, in \u001b[0;36mRenderer.save\u001b[0;34m(self_or_cls, obj, basename, fmt, key, info, options, resources, title, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m     plot\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39msave(basename, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, resources\u001b[38;5;241m=\u001b[39mresources, title\u001b[38;5;241m=\u001b[39mtitle)\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 627\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[43mself_or_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rendered \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    629\u001b[0m (data, info) \u001b[38;5;241m=\u001b[39m rendered\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/plotting/renderer.py:201\u001b[0m, in \u001b[0;36mRenderer.__call__\u001b[0;34m(self, obj, fmt, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_html(plot), info\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_figure_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_post_render_hooks(data, obj, fmt)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, info\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/holoviews/plotting/bokeh/renderer.py:131\u001b[0m, in \u001b[0;36mBokehRenderer._figure_data\u001b[0;34m(self, plot, fmt, doc, as_script, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbokeh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_screenshot_as_png\n\u001b[0;32m--> 131\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mget_screenshot_as_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwebdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     imgByteArr \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[1;32m    133\u001b[0m     img\u001b[38;5;241m.\u001b[39msave(imgByteArr, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPNG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/export.py:236\u001b[0m, in \u001b[0;36mget_screenshot_as_png\u001b[0;34m(obj, driver, timeout, resources, width, height)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    234\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(html)\n\u001b[0;32m--> 236\u001b[0m web_driver \u001b[38;5;241m=\u001b[39m driver \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mwebdriver_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m web_driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[1;32m    238\u001b[0m web_driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmp\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py:153\u001b[0m, in \u001b[0;36m_WebdriverState.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py:157\u001b[0m, in \u001b[0;36m_WebdriverState.create\u001b[0;34m(self, kind)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kind: DriverKind \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m WebDriver:\n\u001b[0;32m--> 157\u001b[0m     driver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drivers\u001b[38;5;241m.\u001b[39madd(driver)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m driver\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py:175\u001b[0m, in \u001b[0;36m_WebdriverState._create\u001b[0;34m(self, kind)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirefox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m driver\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeither firefox and geckodriver nor a variant of chromium browser and \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    176\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromedriver are available on system PATH. You can install the former \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    177\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install -c conda-forge firefox geckodriver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m driver_kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromium\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_chromium_webdriver()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'."
     ]
    }
   ],
   "source": [
    "hover_cum_pypl = HoverTool(tooltips=[(\"Date\",  \"@time{%m/%d/%Y}\"),\n",
    "                            (\"Cumulative Returns\", \"@cum_returns{0,0.000}\")\n",
    "                           ],\n",
    "                  formatters = {\n",
    "                            '@time': 'datetime'\n",
    "                  }\n",
    "                 )\n",
    "# Create an interactive visaulization with hvplot to plot the cumulative returns for PYPL.\n",
    "pypl_dataframe['cum_returns'] = pypl_dataframe['daily_returns'].cumsum()\n",
    "plot = pypl_dataframe.hvplot(\n",
    "    title=f'PYPL Cumulative Returns: {pypl_dataframe[\"time\"].min().date()} to {pypl_dataframe[\"time\"].max().date()}',\n",
    "#    title='PYPL Cumulative Returns',\n",
    "    x='time',\n",
    "    y='cum_returns',\n",
    "    rot=45\n",
    ")\n",
    "plot.opts(\n",
    "    xlabel='Time',\n",
    "    ylabel='Cumulative Return',\n",
    "    tools=[hover_cum_pypl]\n",
    ")\n",
    "# Save the image\n",
    "hvplot.save(plot, 'Images/PYPL_Cumulative_Returns.png')\n",
    "# Display the plot\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the SQL Queries\n",
    "\n",
    "For this part of the assignment, you’ll continue to analyze a single asset (PYPL) from the ETF. You’ll use advanced SQL queries to optimize the efficiency of accessing data from the database.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "2. Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-05 00:00:00.000000</td>\n",
       "      <td>202.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-06 00:00:00.000000</td>\n",
       "      <td>204.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-25 00:00:00.000000</td>\n",
       "      <td>201.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-26 00:00:00.000000</td>\n",
       "      <td>203.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-27 00:00:00.000000</td>\n",
       "      <td>204.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  daily_returns\n",
       "0  2020-08-05 00:00:00.000000         202.92\n",
       "1  2020-08-06 00:00:00.000000         204.09\n",
       "2  2020-08-25 00:00:00.000000         201.71\n",
       "3  2020-08-26 00:00:00.000000         203.53\n",
       "4  2020-08-27 00:00:00.000000         204.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write a SQL SELECT statement to select the time and close columns \n",
    "# where the PYPL closing price was higher than 200.0.\n",
    "query = \"\"\"\n",
    "SELECT time, close\n",
    "FROM PYPL\n",
    "WHERE close > 200.0\n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "pypl_higher_than_200 = pd.DataFrame(engine.execute(query), columns=['time', 'daily_returns'])\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "display(pypl_higher_than_200.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-24 00:00:00.000000</td>\n",
       "      <td>0.140981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-07 00:00:00.000000</td>\n",
       "      <td>0.140318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-13 00:00:00.000000</td>\n",
       "      <td>0.138700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-06 00:00:00.000000</td>\n",
       "      <td>0.100877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-19 00:00:00.000000</td>\n",
       "      <td>0.093371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-10-24 00:00:00.000000</td>\n",
       "      <td>0.085912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-04 00:00:00.000000</td>\n",
       "      <td>0.080986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-10 00:00:00.000000</td>\n",
       "      <td>0.080863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-04-22 00:00:00.000000</td>\n",
       "      <td>0.075321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-26 00:00:00.000000</td>\n",
       "      <td>0.074656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  daily_returns\n",
       "0  2020-03-24 00:00:00.000000       0.140981\n",
       "1  2020-05-07 00:00:00.000000       0.140318\n",
       "2  2020-03-13 00:00:00.000000       0.138700\n",
       "3  2020-04-06 00:00:00.000000       0.100877\n",
       "4  2018-10-19 00:00:00.000000       0.093371\n",
       "5  2019-10-24 00:00:00.000000       0.085912\n",
       "6  2020-11-04 00:00:00.000000       0.080986\n",
       "7  2020-03-10 00:00:00.000000       0.080863\n",
       "8  2020-04-22 00:00:00.000000       0.075321\n",
       "9  2018-12-26 00:00:00.000000       0.074656"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write a SQL SELECT statement to select the time and daily_returns columns\n",
    "# Sort the results in descending order and return only the top 10 return values\n",
    "query = \"\"\"\n",
    "SELECT time, daily_returns\n",
    "FROM PYPL\n",
    "ORDER BY daily_returns DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "pypl_top_10_returns = pd.DataFrame(engine.execute(query), columns=['time', 'daily_returns'])\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "display(pypl_top_10_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Fintech ETF Portfolio\n",
    "\n",
    "For this part of the assignment, you’ll build the entire ETF portfolio and then evaluate its performance. To do so, you’ll build the ETF portfolio by using SQL joins to combine all the data for each asset.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame.\n",
    "\n",
    "2. Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame.\n",
    "\n",
    "    > **Hint** Assuming that this ETF contains equally weighted returns, you can average the returns for each asset to get the average returns of the portfolio. You can then use the average returns of the portfolio to calculate the annualized returns and the cumulative returns. For the calculation to get the average daily returns for the portfolio, use the following code:\n",
    "    >\n",
    "    > ```python\n",
    "    > etf_portfolio_returns = etf_portfolio['daily_returns'].mean(axis=1)\n",
    "    > ```\n",
    "    >\n",
    "    > You can use the average daily returns of the portfolio the same way that you used the daily returns of a single asset.\n",
    "\n",
    "3. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio.\n",
    "\n",
    "> **Hint**  To calculate the annualized returns, multiply the mean of the `etf_portfolio_returns` values by 252.\n",
    ">\n",
    "> To convert the decimal values to percentages, multiply the results by 100.\n",
    "\n",
    "4. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio.\n",
    "\n",
    "5. Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDOT_daily_returns</th>\n",
       "      <th>GSGDOT_daily_returns</th>\n",
       "      <th>PYPLGDOT_daily_returns</th>\n",
       "      <th>SQGDOT_daily_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-16 00:00:00.000000</th>\n",
       "      <td>-0.023218</td>\n",
       "      <td>-0.016708</td>\n",
       "      <td>-0.005564</td>\n",
       "      <td>0.017339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19 00:00:00.000000</th>\n",
       "      <td>-0.007923</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>-0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20 00:00:00.000000</th>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.009053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21 00:00:00.000000</th>\n",
       "      <td>0.001679</td>\n",
       "      <td>-0.006911</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>-0.007591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22 00:00:00.000000</th>\n",
       "      <td>0.006077</td>\n",
       "      <td>-0.005178</td>\n",
       "      <td>-0.010227</td>\n",
       "      <td>-0.023644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            GDOT_daily_returns  GSGDOT_daily_returns  \\\n",
       "time                                                                   \n",
       "2016-12-16 00:00:00.000000           -0.023218             -0.016708   \n",
       "2016-12-19 00:00:00.000000           -0.007923              0.000795   \n",
       "2016-12-20 00:00:00.000000            0.001261              0.016602   \n",
       "2016-12-21 00:00:00.000000            0.001679             -0.006911   \n",
       "2016-12-22 00:00:00.000000            0.006077             -0.005178   \n",
       "\n",
       "                            PYPLGDOT_daily_returns  SQGDOT_daily_returns  \n",
       "time                                                                      \n",
       "2016-12-16 00:00:00.000000               -0.005564              0.017339  \n",
       "2016-12-19 00:00:00.000000                0.003306             -0.001043  \n",
       "2016-12-20 00:00:00.000000                0.007351              0.009053  \n",
       "2016-12-21 00:00:00.000000                0.008807             -0.007591  \n",
       "2016-12-22 00:00:00.000000               -0.010227             -0.023644  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wreate a SQL query to join each table in the portfolio into a single DataFrame \n",
    "# Use the time column from each table as the basis for the join\n",
    "query = '''\n",
    "SELECT GDOT.time, GDOT.daily_returns, GS.daily_returns, PYPL.daily_returns, SQ.daily_returns\n",
    "FROM GDOT\n",
    "INNER JOIN GS ON GDOT.time = GS.time\n",
    "INNER JOIN PYPL ON GDOT.time = PYPL.time\n",
    "INNER JOIN SQ ON GDOT.time = SQ.time\n",
    "'''\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "etf_portfolio = pd.DataFrame(\n",
    "    engine.execute(query), \n",
    "    columns=['time', 'GDOT_daily_returns', 'GSGDOT_daily_returns', 'PYPLGDOT_daily_returns', 'SQGDOT_daily_returns']\n",
    ")\n",
    "etf_portfolio.set_index('time', inplace=True)\n",
    "# Review the resulting DataFrame\n",
    "display(etf_portfolio.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_daily_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-16 00:00:00.000000</th>\n",
       "      <td>-0.007038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19 00:00:00.000000</th>\n",
       "      <td>-0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20 00:00:00.000000</th>\n",
       "      <td>0.008567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21 00:00:00.000000</th>\n",
       "      <td>-0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22 00:00:00.000000</th>\n",
       "      <td>-0.008243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-30 00:00:00.000000</th>\n",
       "      <td>-0.014635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01 00:00:00.000000</th>\n",
       "      <td>-0.003990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02 00:00:00.000000</th>\n",
       "      <td>-0.006288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03 00:00:00.000000</th>\n",
       "      <td>0.011246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04 00:00:00.000000</th>\n",
       "      <td>0.009108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_daily_return\n",
       "time                                         \n",
       "2016-12-16 00:00:00.000000          -0.007038\n",
       "2016-12-19 00:00:00.000000          -0.001216\n",
       "2016-12-20 00:00:00.000000           0.008567\n",
       "2016-12-21 00:00:00.000000          -0.001004\n",
       "2016-12-22 00:00:00.000000          -0.008243\n",
       "...                                       ...\n",
       "2020-11-30 00:00:00.000000          -0.014635\n",
       "2020-12-01 00:00:00.000000          -0.003990\n",
       "2020-12-02 00:00:00.000000          -0.006288\n",
       "2020-12-03 00:00:00.000000           0.011246\n",
       "2020-12-04 00:00:00.000000           0.009108\n",
       "\n",
       "[999 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Extract date value from string on each row\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ---There is probably a more efficient way to do this ---\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m etf_portfolio_returns\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m---> 16\u001b[0m     etf_portfolio_returns\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime_from_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43metf_portfolio_returns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     etf_portfolio_returns\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m etf_portfolio_returns\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdate()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Set the new date column to be the index for the dataframe\u001b[39;00m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mdatetime_from_string\u001b[0;34m(date_str)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdatetime_from_string\u001b[39m(date_str):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(date_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame that displays the mean value of the “daily_returns” columns for all four assets.\n",
    "etf_portfolio_returns = pd.DataFrame(etf_portfolio.mean(axis=1), columns=['mean_daily_return'])\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "display(etf_portfolio_returns)\n",
    "# Function to convert date string to datetime format\n",
    "def datetime_from_string(date_str):\n",
    "    return dt.datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "# Create new date column from date index\n",
    "etf_portfolio_returns['date'] = etf_portfolio_returns.index\n",
    "\n",
    "# Extract date value from string on each row\n",
    "# ---There is probably a more efficient way to do this ---\n",
    "for i in etf_portfolio_returns.index:\n",
    "    etf_portfolio_returns.loc[i, 'date'] = datetime_from_string(etf_portfolio_returns.loc[i, 'date'])\n",
    "    etf_portfolio_returns.loc[i, 'date'] = etf_portfolio_returns.loc[i, 'date'].date()\n",
    "\n",
    "# Set the new date column to be the index for the dataframe\n",
    "etf_portfolio_returns.set_index('date', inplace=True)\n",
    "# Display the new format\n",
    "display(etf_portfolio_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use the average daily returns in the etf_portfolio_returns DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     68\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use the average daily returns provided by the etf_portfolio_returns DataFrame \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# to calculate the annualized return for the portfolio. \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m annualized_etf_portfolio_returns \u001b[38;5;241m=\u001b[39m \u001b[43metf_portfolio_returns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m252\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the annualized return value of the ETF portfolio.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m display(annualized_etf_portfolio_returns)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:116\u001b[0m, in \u001b[0;36mOpsMixin.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__mul__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:6946\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6942\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[1;32m   6944\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 6946\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:6973\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   6970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[1;32m   6971\u001b[0m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[1;32m   6972\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6973\u001b[0m         bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(bm)\n\u001b[1;32m   6976\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:302\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callable(f):\n\u001b[0;32m--> 302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/blocks.py:402\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:222\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m--> 222\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:170\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:127\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    124\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 127\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m np\u001b[38;5;241m.\u001b[39mputmask(result, \u001b[38;5;241m~\u001b[39mmask, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m    130\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "# Use the average daily returns provided by the etf_portfolio_returns DataFrame \n",
    "# to calculate the annualized return for the portfolio. \n",
    "annualized_etf_portfolio_returns = etf_portfolio_returns * np.sqrt(252)\n",
    "\n",
    "# Display the annualized return value of the ETF portfolio.\n",
    "display(annualized_etf_portfolio_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the average daily returns provided by the etf_portfolio_returns DataFrame \n",
    "# to calculate the cumulative returns\n",
    "etf_cumulative_returns = etf_portfolio_returns.cumsum()\n",
    "\n",
    "# Rename the column\n",
    "etf_cumulative_returns.rename(columns={'mean_daily_return': 'cumulative_return'}, inplace=True)\n",
    "\n",
    "# Display the final cumulative return value\n",
    "display(etf_cumulative_returns.tail(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'etf_cumulative_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hover_cum_etf \u001b[38;5;241m=\u001b[39m HoverTool(tooltips\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@date\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY}\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      2\u001b[0m                             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCumulative Return\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@cumulative_return\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0,0.000}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m                            ],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m                   }\n\u001b[1;32m      7\u001b[0m                  )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Using hvplot, create an interactive line plot that visualizes the ETF portfolios cumulative return values.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m etf_plot \u001b[38;5;241m=\u001b[39m \u001b[43metf_cumulative_returns\u001b[49m\u001b[38;5;241m.\u001b[39mhvplot\u001b[38;5;241m.\u001b[39mline(\n\u001b[1;32m     10\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETF Portfolio Cumulative Returns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00metf_cumulative_returns\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00metf_cumulative_returns\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#    title='ETF Portfolio Cumulative Returns',\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m etf_plot\u001b[38;5;241m.\u001b[39mopts(\n\u001b[1;32m     15\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m     ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Return\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[hover_cum_etf]\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the image\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'etf_cumulative_returns' is not defined"
     ]
    }
   ],
   "source": [
    "hover_cum_etf = HoverTool(tooltips=[(\"Date\",  \"@date{%m/%d/%Y}\"),\n",
    "                            (\"Cumulative Return\", \"@cumulative_return{0,0.000}\")\n",
    "                           ],\n",
    "                  formatters = {\n",
    "                            '@date': 'datetime'\n",
    "                  }\n",
    "                 )\n",
    "# Using hvplot, create an interactive line plot that visualizes the ETF portfolios cumulative return values.\n",
    "etf_plot = etf_cumulative_returns.hvplot.line(\n",
    "    title=f'ETF Portfolio Cumulative Returns: {etf_cumulative_returns.index.min()} to {etf_cumulative_returns.index.max()}', \n",
    "#    title='ETF Portfolio Cumulative Returns',\n",
    "    x='date'\n",
    ")\n",
    "etf_plot.opts(\n",
    "    xlabel='Date',\n",
    "    ylabel='Cumulative Return',\n",
    "    tools=[hover_cum_etf]\n",
    ")\n",
    "\n",
    "# Save the image\n",
    "hvplot.save(etf_plot, 'Images/ETF_Portfolio_Cumulative_Returns.png')\n",
    "# Display the plot\n",
    "etf_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
